{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4f2c70",
   "metadata": {},
   "source": [
    "# New York Apartments Scraper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5e4c6",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "To determine the affordability of New York apartments, data will be extracted from Rentals.com as they have over 10,000 units listed at a time. Information such as the price, number of bedroom and bathrooms will be scraped from the corresponding HTML tag using the Selenium library in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7a25f",
   "metadata": {},
   "source": [
    "### Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import csv \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a978b5b",
   "metadata": {},
   "source": [
    "### Open a Chromium Brower\n",
    "\n",
    "Selenium uses a Chromium browser to know which tab to scrape information from. The following code will open a chromium browser located on my local computer and direct it to Rentals.com's website that displays New York City's apartment listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25605464",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Service('C:/chromedriver')\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "URL = \"https://www.rentals.com/New-York/New-York-City/?page=1\"\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93810e",
   "metadata": {},
   "source": [
    "### Scraping\n",
    "\n",
    "Rentals.com seperates their listings by pages with each page having 30 listings. So first, we will determine the number of pages then we will loop through each page to get the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the number of pages of listings.\n",
    "pages = int(driver.find_elements(By.XPATH, '//div[@data-tid=\"pagination_page_count\"]')[0].text.split(\" \")[-1])\n",
    "\n",
    "#Each listing will represent one row, and will be store as a nested list into rows.\n",
    "rows = []\n",
    "\n",
    "#Loop through every page.\n",
    "for page in range(0, pages):\n",
    "    \n",
    "    #Redirect the chromium browser to the current page\n",
    "    URL = \"https://www.rentals.com/New-York/New-York-City/?page=\" + str(page+1)\n",
    "    driver.get(URL)\n",
    "    \n",
    "    #Each listing has a unique ID that is used to navigate to their individual page.\n",
    "    #Each page of listings has a list of IDs, that list will be stored into houses\n",
    "    houses = driver.find_elements(By.XPATH, '//div[@data-tid=\"listing-section\"]')\n",
    "    \n",
    "    #Each unit in a page will have their own link\n",
    "    links = []\n",
    "    \n",
    "    #There are 31 units per page instead of 30 as there's an additional one for ads\n",
    "    house_per_page = 31\n",
    "    \n",
    "    for i in range(house_per_page):\n",
    "        try:\n",
    "            #Each link is just the base URL plus the unique ID\n",
    "            links.append(\"https://www.rentals.com/New-York/New-York/\" + houses[i].get_attribute(\"id\"))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for link in links:\n",
    "        #Navigate to each unit by using their unique link\n",
    "        driver.get(link)\n",
    "        \n",
    "        #All the information is stored in this variable\n",
    "        #I located it by using CSS selector as the div tag doesn't have an ID or class name to reference.\n",
    "        general_info = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"._3EHgB\"))).text.split(\"\\n\")\n",
    "\n",
    "        #Price is the first item in the list.\n",
    "        price = general_info[0]\n",
    "        \n",
    "        #Address isn't stored in general_info so another command is needed.\n",
    "        address_headline = driver.find_element(By.XPATH, '//div[@data-tid=\"address_headline\"]').text\n",
    "        if (address_headline):\n",
    "            street = address_headline\n",
    "        else:\n",
    "            #Sometimes the apartment includes their name in the address headline and places their actual address in a different tag.\n",
    "            street = driver.find_element(By.XPATH, '//div[@data-tid=\"property_label_headline\"]').text\n",
    "            \n",
    "        #Loop through general_info to find where the city, state, and zipcode information is.\n",
    "        for info in general_info:\n",
    "            #The order of city_state_zipcode isn't constant in general_info so I use Regular Expression to pinpoint the information.\n",
    "            city_state_zipcode = re.findall(\".*, .{2} \\d{5}$\",info)\n",
    "            if(city_state_zipcode):\n",
    "                city_state_zipcode = city_state_zipcode[0]\n",
    "                #Break the loop once the information is found\n",
    "                break\n",
    "\n",
    "        #Bedroom and bathroom information isn't located in general information either.\n",
    "        bed_bath = driver.find_element(By.XPATH, '//span[@data-tid=\"bed_bath_section\"]').text.split(\",\")\n",
    "        try:\n",
    "            #bedroom is the first element\n",
    "            bed = bed_bath[0].strip()\n",
    "        except:\n",
    "            #Sometimes there are edge cases where there aren't any bedroom or bathroom information\n",
    "            bed = \"NA\"\n",
    "        try:\n",
    "            #bathroom is the second element\n",
    "            bathroom = bed_bath[1].strip()\n",
    "        except:\n",
    "            bathroom = \"NA\"\n",
    "            \n",
    "        #Compile the disired data into a list and add it to rows\n",
    "        data = [price, bed, bathroom, street, city_state_zipcode]\n",
    "        rows.append(data)\n",
    "        \n",
    "        #Reset the information for the next iteration.\n",
    "        price = \"\"\n",
    "        bed = \"\"\n",
    "        bathroom = \"\"\n",
    "        street = \"\"\n",
    "        city_state_zipcode = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc1691a",
   "metadata": {},
   "source": [
    "### Save the Data\n",
    "\n",
    "Lastly, export the data as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will be the column name in the csv file\n",
    "fields = [\"price\", \"number_of_beds\", \"number_of_bathrooms\", \"street\", \"city_state_zipcode\"] \n",
    "filename = \"9-15-2022 NY Rental Data.csv\"\n",
    "    \n",
    "with open(filename, 'w', newline='', encoding=\"utf-8\") as csvfile: \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "    csvwriter.writerow(fields) \n",
    "    csvwriter.writerows(rows)\n",
    "\n",
    "#Read the csv file to ensure that the correct number of entries were written\n",
    "csvFile = pd.read_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
